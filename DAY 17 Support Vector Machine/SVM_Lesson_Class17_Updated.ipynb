{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0832e810",
   "metadata": {},
   "source": [
    "# üìò Class 17 ‚Äì Introduction to Support Vector Machines (SVM)\n",
    "**Duration:** 2 Hours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6745f",
   "metadata": {},
   "source": [
    "### üéØ Objective\n",
    "By the end of this lesson, you will understand how Support Vector Machines (SVM) work for classification tasks, including:\n",
    "- Linear and Non-linear classification\n",
    "- Kernels and their usage\n",
    "- Concepts of hyperplanes and margins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427bf39c",
   "metadata": {},
   "source": [
    "## 1. üìå Introduction to Support Vector Machines\n",
    "Support Vector Machines (SVMs) are supervised learning algorithms used mainly for classification. They work by finding the best boundary (called a **hyperplane**) that separates classes of data. SVM tries to find a hyperplane that best divides the data into classes by maximizing the margin between the classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d340a",
   "metadata": {},
   "source": [
    "### üß† Key Concepts:\n",
    "- **Hyperplane**: A hyperplane is a decision boundary that separates different classes. In a 2D space, it‚Äôs a line, and in higher dimensions, it‚Äôs a plane or hyperplane. Think of a wall that separates two groups in a room.\n",
    "- **Margin**: The margin is the distance between the hyperplane and the closest data points from each class (known as support vectors). SVM aims to maximize this margin for better generalization. The space between the wall (hyperplane) and the nearest object (support vectors).\n",
    "- **Support Vectors**: Data points that are closest to the hyperplane and influence its position.\n",
    "- **Kernels**: Techniques that help SVM deal with non-linear data by transforming it into a higher-dimensional space.\n",
    "\n",
    "Non-linear Classification (Kernels):\n",
    "\n",
    "\n",
    "SVM can also handle non-linearly separable data by using kernels to transform the data into higher dimensions where it becomes linearly separable.\n",
    "\n",
    "\n",
    "Common kernels:\n",
    "\n",
    "\n",
    "Linear Kernel: For linearly separable data.\n",
    "\n",
    "\n",
    "Polynomial Kernel: For data that requires a polynomial decision boundary.\n",
    "\n",
    "\n",
    "RBF Kernel (Radial Basis Function): For complex non-linear data, it maps data to an infinite-dimensional space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46ec33",
   "metadata": {},
   "source": [
    "## 2. ‚öôÔ∏è How SVM Works\n",
    "### Linear SVM\n",
    "Linear SVM tries to find the best straight line (or plane) to separate data.\n",
    "Finds the hyperplane that best separates the data by maximizing the margin. It uses support vectors (the closest data points) to define the margin.\n",
    "\n",
    "\n",
    "### Non-linear SVM\n",
    "If the data cannot be separated by a straight line, we use **Kernels** to transform it into a space where it can be.\n",
    "When data is not linearly separable, SVM uses kernel functions to map the data into a higher-dimensional space where a linear hyperplane can be found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5633fa30",
   "metadata": {},
   "source": [
    "## 3. üíª Implementing SVM with Scikit-Learn (Linear Kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f21ac9",
   "metadata": {},
   "source": [
    "### üì¶ Step 1: Import Libraries\n",
    "We import libraries like pandas, matplotlib, and sklearn for loading, processing, and modeling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec917fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2247e03",
   "metadata": {},
   "source": [
    "### üìä Step 2: Load Dataset\n",
    "We are using the **Breast Cancer Dataset**, which contains features of tumors and the goal is to classify them as malignant or benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c074ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e9294f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05b82a",
   "metadata": {},
   "source": [
    "### üßπ Step 3: Preprocess the Data\n",
    "We separate the features (X) and the target variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a9da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab746c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851067b",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Step 4: Split the Data into Train and Test\n",
    "We split the data so the model can learn on one part and we can test it on another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36b003f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f36ee",
   "metadata": {},
   "source": [
    "### ü§ñ Step 5: Create SVM Model with Linear Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f20c751",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è FIX: Feature Scaling Added for SVM\n",
    "SVM is sensitive to the scale of features. Without scaling, training can become extremely slow or inaccurate.\n",
    "We apply **StandardScaler** to normalize features to zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbad3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Re-split the scaled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca00ddd",
   "metadata": {},
   "source": [
    "### ‚úÖ Training SVM Model (Linear Kernel) with Scaled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56dd09e",
   "metadata": {},
   "source": [
    "### üß™ Step 7: Evaluate the Model\n",
    "We check how well the model did using accuracy and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM Accuracy: \", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22739d6",
   "metadata": {},
   "source": [
    "### üìä Step 8: Visualize the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de04a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=svm_model.classes_, yticklabels=svm_model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for SVM (Linear Kernel)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1007985",
   "metadata": {},
   "source": [
    "## 4. üåå Understanding the Impact of Kernels ‚Äì RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel='rbf')\n",
    "svm_rbf_model.fit(X_train, y_train)\n",
    "\n",
    "y_rbf_pred = svm_rbf_model.predict(X_test)\n",
    "\n",
    "accuracy_rbf = accuracy_score(y_test, y_rbf_pred)\n",
    "print(\"SVM with RBF Kernel Accuracy: \", accuracy_rbf)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_rbf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47392312",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rbf = confusion_matrix(y_test, y_rbf_pred)\n",
    "sns.heatmap(cm_rbf, annot=True, fmt='d', cmap='Blues', xticklabels=svm_rbf_model.classes_, yticklabels=svm_rbf_model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for SVM with RBF Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda54466",
   "metadata": {},
   "source": [
    "## 5. üñºÔ∏è Visualizing SVM Decision Boundaries (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20646829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X_vis, y_vis = make_classification(n_samples=100, n_features=2, n_classes=2, n_clusters_per_class=1, random_state=42)\n",
    "\n",
    "svm_vis_model = SVC(kernel='linear')\n",
    "svm_vis_model.fit(X_vis, y_vis)\n",
    "\n",
    "xx, yy = np.meshgrid(np.linspace(X_vis[:, 0].min(), X_vis[:, 0].max(), 100),\n",
    "                     np.linspace(X_vis[:, 1].min(), X_vis[:, 1].max(), 100))\n",
    "Z = svm_vis_model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "plt.scatter(X_vis[:, 0], X_vis[:, 1], c=y_vis, edgecolors='k', s=100)\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('SVM Decision Boundary (Linear Kernel)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3177c69",
   "metadata": {},
   "source": [
    "## 6. üîç Comparison of Linear vs. Non-Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689e358",
   "metadata": {},
   "source": [
    "\n",
    "| Feature            | Linear SVM                     | Non-Linear SVM (Kernel)        |\n",
    "|--------------------|--------------------------------|--------------------------------|\n",
    "| Suitable for       | Linearly separable data        | Non-linearly separable data    |\n",
    "| Transformation     | Not required                   | Required using kernel tricks   |\n",
    "| Kernel             | Linear                         | RBF, Polynomial, Sigmoid       |\n",
    "| Speed              | Faster                         | Slower due to transformation   |\n",
    "\n",
    "‚û°Ô∏è **Activity Suggestion**: Try training SVM with different kernels on the same dataset and observe the accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
